{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "misisng ticker dataAMAT\n",
      "misisng ticker dataT\n",
      "60\n",
      "70\n",
      "misisng ticker dataBRK.B\n",
      "80\n",
      "misisng ticker dataBF.B\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "misisng ticker dataDAL\n",
      "150\n",
      "misisng ticker dataDG\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "misisng ticker dataBEN\n",
      "misisng ticker dataFCX\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "misisng ticker dataLEN\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "misisng ticker dataNWS\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "misisng ticker dataLUV\n",
      "misisng ticker dataSTT\n",
      "430\n",
      "misisng ticker dataTGT\n",
      "440\n",
      "450\n",
      "460\n",
      "misisng ticker dataUNM\n",
      "470\n",
      "misisng ticker dataVRSK\n",
      "misisng ticker dataVRTX\n",
      "480\n",
      "misisng ticker dataWM\n",
      "490\n",
      "500\n",
      "                  MMM        ABT  ABBV  ACN      ATVI  AYI       ADBE     AMD  \\\n",
      "Date                                                                            \n",
      "2000-01-03  30.614885  10.056676   NaN  NaN  1.251975  NaN  16.274672  15.500   \n",
      "2000-01-04  29.398392   9.769344   NaN  NaN  1.213892  NaN  14.909399  14.625   \n",
      "2000-01-05  30.249941   9.751384   NaN  NaN  1.218653  NaN  15.204174  15.000   \n",
      "2000-01-06  32.682892  10.092591   NaN  NaN  1.194851  NaN  15.328290  16.000   \n",
      "2000-01-07  33.331699  10.200341   NaN  NaN  1.228173  NaN  16.072987  16.250   \n",
      "\n",
      "            AAP        AES ...   WYNN       XEL        XRX       XLNX  \\\n",
      "Date                       ...                                          \n",
      "2000-01-03  NaN  31.310091 ...    NaN  8.465485  49.975788  34.724194   \n",
      "2000-01-04  NaN  30.068480 ...    NaN  8.660414  47.651325  33.935005   \n",
      "2000-01-05  NaN  30.392372 ...    NaN  8.994577  50.104916  33.192238   \n",
      "2000-01-06  NaN  30.635298 ...    NaN  8.911037  49.071815  30.314034   \n",
      "2000-01-07  NaN  31.229115 ...    NaN  8.911037  50.234047  33.749325   \n",
      "\n",
      "                   XL  XYL       YUM  ZBH       ZION  ZTS  \n",
      "Date                                                       \n",
      "2000-01-03  31.850992  NaN  5.182341  NaN  43.515522  NaN  \n",
      "2000-01-04  30.417316  NaN  5.078173  NaN  41.408337  NaN  \n",
      "2000-01-05  30.688551  NaN  5.104214  NaN  41.359329  NaN  \n",
      "2000-01-06  30.921043  NaN  5.060811  NaN  41.947392  NaN  \n",
      "2000-01-07  32.974693  NaN  4.947962  NaN  42.045391  NaN  \n",
      "\n",
      "[5 rows x 488 columns]\n"
     ]
    }
   ],
   "source": [
    "import bs4 as bs\n",
    "import datetime as dt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker)\n",
    "        \n",
    "    with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
    "        pickle.dump(tickers,f)\n",
    "        \n",
    "    return tickers\n",
    "\n",
    "#save_sp500_tickers()\n",
    "\n",
    "\n",
    "def get_data_from_yahoo(reload_sp500=False):\n",
    "    \n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\",\"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "    \n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "\n",
    "    start = dt.datetime(2000, 1, 1)\n",
    "    end = dt.datetime(2016, 12, 31)\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        # just in case your connection breaks, we'd like to save our progress!\n",
    "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "            try:\n",
    "                df = web.DataReader(ticker, \"yahoo\", start, end)\n",
    "                df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "            except:\n",
    "                  print(\"still not working ! bad ticker need to investiagte\" + ticker)\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "\n",
    "#get_data_from_yahoo()\n",
    "\n",
    "def compile_data():\n",
    "    with open(\"sp500tickers.pickle\",\"rb\") as f:\n",
    "        tickers = pickle.load(f)\n",
    "\n",
    "    main_df = pd.DataFrame()\n",
    "    \n",
    "    for count,ticker in enumerate(tickers):\n",
    "        try:\n",
    "            df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "            df.set_index('Date', inplace=True)\n",
    "\n",
    "            df.rename(columns={'Adj Close':ticker}, inplace=True)\n",
    "            df.drop(['Open','High','Low','Close','Volume'],1,inplace=True)\n",
    "\n",
    "            if main_df.empty:\n",
    "                main_df = df\n",
    "            else:\n",
    "                main_df = main_df.join(df, how='outer')\n",
    "\n",
    "            if count % 10 == 0:\n",
    "                print(count)\n",
    "        except:\n",
    "            print(\"misisng ticker data\" + ticker)\n",
    "    print(main_df.head())\n",
    "    main_df.to_csv('sp500_joined_closes.csv')\n",
    "\n",
    "\n",
    "compile_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:avinpy35]",
   "language": "python",
   "name": "conda-env-avinpy35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
